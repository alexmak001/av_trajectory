{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"D:/School/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "#train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop,scalingFactor):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            x = temp_dataset[i][0]/scalingFactor\n",
    "            y = temp_dataset[i][1]/scalingFactor\n",
    "            samples.append((x,y))\n",
    "            \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.01\n",
    "seqLen = 50\n",
    "stepSize = 5\n",
    "batch_sz = 64  # batch size \n",
    "scaling_factor = 1000 # divides each value by this number to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2035"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData,scaling_factor)\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-8e56f7b34fb3>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24420"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "len(train_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([ 1.5579, -1.8898,  1.5581, -1.8894,  1.5583, -1.8888,  1.5585, -1.8882,\n",
       "           1.5588, -1.8875,  1.5591, -1.8866,  1.5594, -1.8857,  1.5598, -1.8848,\n",
       "           1.5602, -1.8838,  1.5606, -1.8828,  1.5609, -1.8819,  1.5613, -1.8810,\n",
       "           1.5617, -1.8801,  1.5620, -1.8791,  1.5624, -1.8782,  1.5628, -1.8773,\n",
       "           1.5631, -1.8764,  1.5635, -1.8755,  1.5638, -1.8746,  1.5642, -1.8737,\n",
       "           1.5645, -1.8727,  1.5649, -1.8718,  1.5652, -1.8709,  1.5656, -1.8700,\n",
       "           1.5659, -1.8691,  1.5663, -1.8682,  1.5666, -1.8673,  1.5670, -1.8664,\n",
       "           1.5673, -1.8655,  1.5677, -1.8646,  1.5680, -1.8638,  1.5684, -1.8629,\n",
       "           1.5687, -1.8620,  1.5690, -1.8612,  1.5694, -1.8603,  1.5697, -1.8595,\n",
       "           1.5700, -1.8586,  1.5704, -1.8578,  1.5707, -1.8570,  1.5710, -1.8561,\n",
       "           1.5713, -1.8553,  1.5716, -1.8546,  1.5719, -1.8538,  1.5722, -1.8530,\n",
       "           1.5725, -1.8523,  1.5728, -1.8515,  1.5731, -1.8508,  1.5734, -1.8501,\n",
       "           1.5737, -1.8494,  1.5739, -1.8487], device='cuda:0'),\n",
       "  tensor([ 1.5740, -1.8480], device='cuda:0')),\n",
       " 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be a vector of size (2*seqLen,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, tensor([ 1.5740, -1.8480], device='cuda:0'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "#num_epochs = 60\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = seqLen*2 #number of features\n",
    "hidden_size = 128 #number of features in hidden state\n",
    "num_layers = 2 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, hidden_size):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(inputSize, hidden_size)\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linearRegression(\n",
       "  (linear1): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = linearRegression(input_size, output_size, hidden_size)\n",
    "lr = lr.to(device)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(lr.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.01738375\n",
      "epoch:  10 loss: 0.00339728\n",
      "epoch:  20 loss: 0.00181302\n",
      "epoch:  30 loss: 0.00101192\n",
      "epoch:  40 loss: 0.00060252\n",
      "epoch:  50 loss: 0.00039042\n",
      "epoch:  60 loss: 0.00027862\n",
      "epoch:  70 loss: 0.00021836\n",
      "epoch:  80 loss: 0.00018503\n",
      "epoch:  90 loss: 0.00016602\n",
      "epoch: 100 loss: 0.00015481\n",
      "epoch: 110 loss: 0.00014797\n",
      "epoch: 120 loss: 0.00014364\n",
      "epoch: 130 loss: 0.00014080\n",
      "epoch: 140 loss: 0.00013887\n",
      "epoch: 150 loss: 0.00013751\n",
      "epoch: 160 loss: 0.00013652\n",
      "epoch: 170 loss: 0.00013577\n",
      "epoch: 180 loss: 0.00013518\n",
      "epoch: 190 loss: 0.00013470\n",
      "epoch: 199 loss: 0.0001343318\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_loader:\n",
    "        lr.train()\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #lr.hidden_cell = (torch.zeros(num_layers, 1, lr.hidden_layer_size).to(device),torch.zeros(num_layers, 1, lr.hidden_layer_size).to(device))\n",
    "        \n",
    "        \n",
    "        y_pred = lr(seq)\n",
    "        \n",
    "        #print(seq.shape)\n",
    "        #print(y_pred.shape, labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "    if i%50 == 0:\n",
    "        modelPath = \"lrTorchEpoch{0}.pt\".format(i)\n",
    "        torch.save(lr.state_dict(), modelPath)\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy()*scaling_factor)\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempValDF = validation(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempValDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0_austin\n",
       "1             1_austin\n",
       "2             2_austin\n",
       "3             3_austin\n",
       "4             4_austin\n",
       "             ...      \n",
       "1681    1681_palo-alto\n",
       "1682    1682_palo-alto\n",
       "1683    1683_palo-alto\n",
       "1684    1684_palo-alto\n",
       "1685    1685_palo-alto\n",
       "Name: ID, Length: 29843, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPredFinal = pd.concat(tempValDF)\n",
    "lrPredFinal.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPredFinal.to_csv(\"lrtorch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lr.state_dict(), \"lrtorchfinal.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.640423e+03</td>\n",
       "      <td>-5.746916e+05</td>\n",
       "      <td>8.036583e+03</td>\n",
       "      <td>-5.739679e+05</td>\n",
       "      <td>7.921162e+03</td>\n",
       "      <td>-5.730536e+05</td>\n",
       "      <td>8.366955e+03</td>\n",
       "      <td>-5.727774e+05</td>\n",
       "      <td>8.532963e+03</td>\n",
       "      <td>-5.737065e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.719129e+05</td>\n",
       "      <td>1.906464e+03</td>\n",
       "      <td>-5.719819e+05</td>\n",
       "      <td>2.837086e+03</td>\n",
       "      <td>-5.718892e+05</td>\n",
       "      <td>2.998597e+03</td>\n",
       "      <td>-5.724570e+05</td>\n",
       "      <td>2.732193e+03</td>\n",
       "      <td>-5.724031e+05</td>\n",
       "      <td>0_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.471135e+05</td>\n",
       "      <td>2.434854e+04</td>\n",
       "      <td>-3.473527e+05</td>\n",
       "      <td>2.380774e+04</td>\n",
       "      <td>-3.473492e+05</td>\n",
       "      <td>2.371947e+04</td>\n",
       "      <td>-3.475309e+05</td>\n",
       "      <td>2.334900e+04</td>\n",
       "      <td>-3.483431e+05</td>\n",
       "      <td>2.355387e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121599e+04</td>\n",
       "      <td>-3.486686e+05</td>\n",
       "      <td>2.144767e+04</td>\n",
       "      <td>-3.489024e+05</td>\n",
       "      <td>2.134151e+04</td>\n",
       "      <td>-3.487441e+05</td>\n",
       "      <td>2.159085e+04</td>\n",
       "      <td>-3.488446e+05</td>\n",
       "      <td>2.129664e+04</td>\n",
       "      <td>1_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.093472e+04</td>\n",
       "      <td>-2.475840e+05</td>\n",
       "      <td>5.093151e+04</td>\n",
       "      <td>-2.475861e+05</td>\n",
       "      <td>5.092859e+04</td>\n",
       "      <td>-2.475858e+05</td>\n",
       "      <td>5.092356e+04</td>\n",
       "      <td>-2.475859e+05</td>\n",
       "      <td>5.091556e+04</td>\n",
       "      <td>-2.475804e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.474736e+05</td>\n",
       "      <td>5.077775e+04</td>\n",
       "      <td>-2.474697e+05</td>\n",
       "      <td>5.077187e+04</td>\n",
       "      <td>-2.474680e+05</td>\n",
       "      <td>5.076967e+04</td>\n",
       "      <td>-2.474632e+05</td>\n",
       "      <td>5.076676e+04</td>\n",
       "      <td>-2.474626e+05</td>\n",
       "      <td>2_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.137234e+05</td>\n",
       "      <td>1.795034e+06</td>\n",
       "      <td>-1.136632e+05</td>\n",
       "      <td>1.795161e+06</td>\n",
       "      <td>-1.136764e+05</td>\n",
       "      <td>1.795153e+06</td>\n",
       "      <td>-1.136526e+05</td>\n",
       "      <td>1.795231e+06</td>\n",
       "      <td>-1.134506e+05</td>\n",
       "      <td>1.795178e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.794926e+06</td>\n",
       "      <td>-1.122399e+05</td>\n",
       "      <td>1.794846e+06</td>\n",
       "      <td>-1.121771e+05</td>\n",
       "      <td>1.794854e+06</td>\n",
       "      <td>-1.122089e+05</td>\n",
       "      <td>1.794780e+06</td>\n",
       "      <td>-1.121609e+05</td>\n",
       "      <td>1.794844e+06</td>\n",
       "      <td>3_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.167985e+06</td>\n",
       "      <td>-6.255224e+05</td>\n",
       "      <td>1.168758e+06</td>\n",
       "      <td>-6.265594e+05</td>\n",
       "      <td>1.168962e+06</td>\n",
       "      <td>-6.277429e+05</td>\n",
       "      <td>1.168398e+06</td>\n",
       "      <td>-6.281635e+05</td>\n",
       "      <td>1.168051e+06</td>\n",
       "      <td>-6.268896e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.285362e+05</td>\n",
       "      <td>1.176362e+06</td>\n",
       "      <td>-6.283761e+05</td>\n",
       "      <td>1.175101e+06</td>\n",
       "      <td>-6.284988e+05</td>\n",
       "      <td>1.174925e+06</td>\n",
       "      <td>-6.276844e+05</td>\n",
       "      <td>1.175249e+06</td>\n",
       "      <td>-6.277981e+05</td>\n",
       "      <td>4_austin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             v0            v1            v2            v3            v4  \\\n",
       "0  8.640423e+03 -5.746916e+05  8.036583e+03 -5.739679e+05  7.921162e+03   \n",
       "1 -3.471135e+05  2.434854e+04 -3.473527e+05  2.380774e+04 -3.473492e+05   \n",
       "2  5.093472e+04 -2.475840e+05  5.093151e+04 -2.475861e+05  5.092859e+04   \n",
       "3 -1.137234e+05  1.795034e+06 -1.136632e+05  1.795161e+06 -1.136764e+05   \n",
       "4  1.167985e+06 -6.255224e+05  1.168758e+06 -6.265594e+05  1.168962e+06   \n",
       "\n",
       "             v5            v6            v7            v8            v9  ...  \\\n",
       "0 -5.730536e+05  8.366955e+03 -5.727774e+05  8.532963e+03 -5.737065e+05  ...   \n",
       "1  2.371947e+04 -3.475309e+05  2.334900e+04 -3.483431e+05  2.355387e+04  ...   \n",
       "2 -2.475858e+05  5.092356e+04 -2.475859e+05  5.091556e+04 -2.475804e+05  ...   \n",
       "3  1.795153e+06 -1.136526e+05  1.795231e+06 -1.134506e+05  1.795178e+06  ...   \n",
       "4 -6.277429e+05  1.168398e+06 -6.281635e+05  1.168051e+06 -6.268896e+05  ...   \n",
       "\n",
       "           v111          v112          v113          v114          v115  \\\n",
       "0 -5.719129e+05  1.906464e+03 -5.719819e+05  2.837086e+03 -5.718892e+05   \n",
       "1  2.121599e+04 -3.486686e+05  2.144767e+04 -3.489024e+05  2.134151e+04   \n",
       "2 -2.474736e+05  5.077775e+04 -2.474697e+05  5.077187e+04 -2.474680e+05   \n",
       "3  1.794926e+06 -1.122399e+05  1.794846e+06 -1.121771e+05  1.794854e+06   \n",
       "4 -6.285362e+05  1.176362e+06 -6.283761e+05  1.175101e+06 -6.284988e+05   \n",
       "\n",
       "           v116          v117          v118          v119        ID  \n",
       "0  2.998597e+03 -5.724570e+05  2.732193e+03 -5.724031e+05  0_austin  \n",
       "1 -3.487441e+05  2.159085e+04 -3.488446e+05  2.129664e+04  1_austin  \n",
       "2  5.076967e+04 -2.474632e+05  5.076676e+04 -2.474626e+05  2_austin  \n",
       "3 -1.122089e+05  1.794780e+06 -1.121609e+05  1.794844e+06  3_austin  \n",
       "4  1.174925e+06 -6.276844e+05  1.175249e+06 -6.277981e+05  4_austin  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrPredFinal.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcb3c223ab97c6437cfd6f554c901fa5c15e7f782458399862988fe58f6c8db1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('PytorchVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
