{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "#import seaborn as sns\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean memory\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "### Change to requried path to access data locally, too big too push all data into github\n",
    "#ROOT_PATH = \"C:/Users/Administrator/cse151b-spring2022/argo2/\"\n",
    "ROOT_PATH = \"D:/School/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(outputs).long()\n",
    "\n",
    "    if split==\"test\":\n",
    "    \n",
    "        return torch.from_numpy(inputs).float(), torch.from_numpy(np.array([]))\n",
    "\n",
    "    \n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None, device='cpu'):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "        self.outputs = self.outputs.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.split == 'train':\n",
    "            data = (self.inputs[idx], self.outputs[idx])\n",
    "        if self.split == 'test':\n",
    "            data = self.inputs[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "#train_dataset  = ArgoverseDataset(city = city, split = split, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to select proportion of a cities random examples w/o replacement from each city and put all data into one list\n",
    "# purpose: whole dataset is too big and might be redundant\n",
    "def randomCitySampler(prop,scalingFactor):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    samples = []\n",
    "    for c in cities:\n",
    "        # get city data\n",
    "        temp_dataset = ArgoverseDataset(city = c, split = \"train\", device=device)\n",
    "\n",
    "        numProp = int(len(temp_dataset) * prop)\n",
    "\n",
    "        # get N number of random indicies\n",
    "        ind = random.sample(range(0, len(temp_dataset)), numProp)\n",
    "        #print(ind)\n",
    "        # push all data indicies into samples list\n",
    "        for i in ind: \n",
    "            x = temp_dataset[i][0]/scalingFactor\n",
    "            y = temp_dataset[i][1]/scalingFactor\n",
    "            samples.append((x,y))\n",
    "            \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants for generating Dataset\n",
    "proportionOfEntireData = 0.5\n",
    "seqLen = 40\n",
    "stepSize = 3\n",
    "batch_sz = 64  # batch size \n",
    "scaling_factor = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create train dataset, with proportion to actual amount data\n",
    "sampleTest = randomCitySampler(proportionOfEntireData,scaling_factor)\n",
    "len(sampleTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequences of length seqLength and specific step size\n",
    "def sequenceGenerator(data, seqLen=40, stepSize=5):\n",
    "    newData = []\n",
    "    for d in data:\n",
    "        # concat X and Y together\n",
    "        temp = torch.cat([d[0],d[1]])\n",
    "        # make X of length SeqLen and Y is next x,y coordinate pair\n",
    "        for i in range(0,len(temp)-seqLen, stepSize):\n",
    "            x = temp[i:i + seqLen]\n",
    "            #flatX = Variable(torch.tensor([item for sublist in x for item in sublist])).to(device)\n",
    "            flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n",
    "            y = temp[i+seqLen]\n",
    "            newData.append((flatX,y))\n",
    "            \n",
    "        \n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8e56f7b34fb3>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  flatX = torch.flatten(Variable(torch.tensor(x)).to(device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2445744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences\n",
    "train_seq_data = sequenceGenerator(sampleTest,seqLen, stepSize)\n",
    "len(train_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([ 0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,\n",
       "           0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,\n",
       "           0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,  0.0707, -0.2968,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,\n",
       "           0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969,  0.0707, -0.2969],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0707, -0.2969], device='cuda:0')),\n",
       " 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be a vector of size (80,2) for each example\n",
    "train_seq_data[0], len(train_seq_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loader\n",
    "train_loader = DataLoader(train_seq_data,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, tensor([ 0.0707, -0.2969], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape is correct\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "len(train_features[0]), train_labels[0]\n",
    "# shape is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "#num_epochs = 60\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = seqLen*2 #number of features\n",
    "hidden_size = 150 #number of features in hidden state\n",
    "num_layers = 2 #number of stacked lstm layers\n",
    "\n",
    "output_size = 2 #number of output classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size,num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size,num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(num_layers,1,self.hidden_layer_size).to(device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(80, 150, num_layers=2)\n",
       "  (linear): Linear(in_features=150, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = LSTM(input_size, hidden_size,output_size,num_layers)\n",
    "lstm = lstm.to(device)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.00000284\n",
      "epoch:  10 loss: 0.00000062\n",
      "epoch:  20 loss: 0.00000033\n",
      "epoch:  30 loss: 0.00000030\n",
      "epoch:  40 loss: 0.00000033\n",
      "epoch:  50 loss: 0.00000029\n",
      "epoch:  60 loss: 0.00000020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-130b1c370374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#print(seq.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-7af5b7432db4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_seq)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_cell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    582\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    583\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_loader:\n",
    "        lstm.train()\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        lstm.hidden_cell = (torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device),\n",
    "                        torch.zeros(num_layers, 1, lstm.hidden_layer_size).to(device))\n",
    "        \n",
    "        \n",
    "        y_pred = lstm(seq)\n",
    "        \n",
    "        #print(seq.shape)\n",
    "        #print(y_pred.shape, labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = loss_function(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f'epoch: {i:3} loss: {loss.item():10.8f}')\n",
    "\n",
    "    if i%30 == 0:\n",
    "        modelPath = \"lstm5Epoch{0}.pt\".format(i)\n",
    "        torch.save(lstm.state_dict(), modelPath)\n",
    "\n",
    "print(f'epoch: {i:3} loss: {loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before normailizing:\n",
    "epoch:   0 loss: 1702641.00000000 \\n\n",
    "epoch:  10 loss: 1387110.12500000\\n\n",
    "epoch:  20 loss: 1210237.00000000\\n\n",
    "epoch:  30 loss: 1043616.93750000\\n\n",
    "epoch:  40 loss: 843062.68750000\\n\n",
    "epoch:  50 loss: 642747.50000000\\n\n",
    "epoch:  60 loss: 454254.09375000\\n\n",
    "epoch:  70 loss: 307120.00000000\\n\n",
    "epoch:  80 loss: 195371.10937500\\n\n",
    "epoch:  90 loss: 145173.21875000\\n\n",
    "epoch: 100 loss: 63596.96093750\\n\n",
    "epoch: 110 loss: 32955.25000000\\n\n",
    "epoch: 120 loss: 30699.15625000\\n\n",
    "epoch: 130 loss: 54998.30468750\\n\n",
    "epoch: 140 loss: 54867.91796875\\n\n",
    "epoch: 149 loss: 41005.5078125000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cycle for each test set and use LSTM to predict \n",
    "# add results for each city to dataframe \n",
    "# concatinate all dataframes\n",
    "\n",
    "def validation(model):\n",
    "    cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\",\"palo-alto\"]\n",
    "\n",
    "    # all the data frames\n",
    "    allDF = []\n",
    "    with torch.no_grad():\n",
    "        for c in cities:\n",
    "            \n",
    "            test_dataset = ArgoverseDataset(city=c, split='test', device=device)\n",
    "            test_loader = DataLoader(test_dataset,batch_size=128)\n",
    "\n",
    "            cityPredictions = []\n",
    "            for t in test_loader.dataset:\n",
    "                model.eval()\n",
    "                flat = torch.flatten(t)\n",
    "                currentPred = []\n",
    "\n",
    "                for i in range(60):\n",
    "                    #print(flat)\n",
    "                    #print(len(flat)-seqLen*2)\n",
    "\n",
    "                    pred = torch.flatten(model(flat[len(flat)-seqLen*2:].view(1,seqLen*2)))\n",
    "\n",
    "                    #print(flat[len(flat)-seqLen*2:].view(1,80))\n",
    "                    #print(pred)\n",
    "\n",
    "                    currentPred.append(pred)\n",
    "\n",
    "                    #print(torch.flatten(pred).shape)\n",
    "                    #print(flat.shape)\n",
    "                    \n",
    "                    flat = torch.cat((flat,pred),0)\n",
    "                    #print(flat)\n",
    "\n",
    "                #print(len(flat[100:]))\n",
    "                cityPredictions.append(flat[100:].detach().to('cpu').numpy()*scaling_factor)\n",
    "        \n",
    "            df = pd.DataFrame(cityPredictions)\n",
    "            df.columns = ['v' + str(i) for i in (range(120))]\n",
    "            df['ID'] = [str(i) + '_' + c for i in (range(len(test_loader.dataset)))]\n",
    "            allDF.append(df)\n",
    "            \n",
    "    return allDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempValDF = validation(lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempValDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0_austin\n",
       "1             1_austin\n",
       "2             2_austin\n",
       "3             3_austin\n",
       "4             4_austin\n",
       "             ...      \n",
       "1681    1681_palo-alto\n",
       "1682    1682_palo-alto\n",
       "1683    1683_palo-alto\n",
       "1684    1684_palo-alto\n",
       "1685    1685_palo-alto\n",
       "Name: ID, Length: 29843, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmPredFinal = pd.concat(tempValDF)\n",
    "lstmPredFinal.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmPredFinal.to_csv(\"lstm5early.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), \"lstm5finalearly.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2966.430664</td>\n",
       "      <td>-9985.373047</td>\n",
       "      <td>697.852295</td>\n",
       "      <td>-10905.495117</td>\n",
       "      <td>690.802124</td>\n",
       "      <td>-10871.316406</td>\n",
       "      <td>-76.476784</td>\n",
       "      <td>-10835.010742</td>\n",
       "      <td>-160.795670</td>\n",
       "      <td>-10610.087891</td>\n",
       "      <td>...</td>\n",
       "      <td>1372.910889</td>\n",
       "      <td>1810.574585</td>\n",
       "      <td>1546.528076</td>\n",
       "      <td>1830.382812</td>\n",
       "      <td>1617.615112</td>\n",
       "      <td>1960.792969</td>\n",
       "      <td>1653.945923</td>\n",
       "      <td>1995.821899</td>\n",
       "      <td>1651.798950</td>\n",
       "      <td>0_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14110.257812</td>\n",
       "      <td>1248.141846</td>\n",
       "      <td>-13425.822266</td>\n",
       "      <td>1427.882446</td>\n",
       "      <td>-14444.098633</td>\n",
       "      <td>1370.556519</td>\n",
       "      <td>-14100.422852</td>\n",
       "      <td>1362.783325</td>\n",
       "      <td>-14071.736328</td>\n",
       "      <td>1510.558472</td>\n",
       "      <td>...</td>\n",
       "      <td>2224.956543</td>\n",
       "      <td>2962.765625</td>\n",
       "      <td>2215.879639</td>\n",
       "      <td>2998.319824</td>\n",
       "      <td>2205.225098</td>\n",
       "      <td>3001.184814</td>\n",
       "      <td>2196.748047</td>\n",
       "      <td>2946.293457</td>\n",
       "      <td>2248.370117</td>\n",
       "      <td>1_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6244.087891</td>\n",
       "      <td>-9125.590820</td>\n",
       "      <td>3489.904785</td>\n",
       "      <td>-10084.924805</td>\n",
       "      <td>4511.722168</td>\n",
       "      <td>-10015.958984</td>\n",
       "      <td>4397.600098</td>\n",
       "      <td>-9890.113281</td>\n",
       "      <td>3239.341309</td>\n",
       "      <td>-9783.153320</td>\n",
       "      <td>...</td>\n",
       "      <td>602.991272</td>\n",
       "      <td>-703.001160</td>\n",
       "      <td>714.663147</td>\n",
       "      <td>-719.726807</td>\n",
       "      <td>774.714661</td>\n",
       "      <td>-622.440613</td>\n",
       "      <td>821.556763</td>\n",
       "      <td>-489.944244</td>\n",
       "      <td>834.670654</td>\n",
       "      <td>2_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1807.790161</td>\n",
       "      <td>12150.986328</td>\n",
       "      <td>4077.757080</td>\n",
       "      <td>11414.631836</td>\n",
       "      <td>1885.708008</td>\n",
       "      <td>11301.711914</td>\n",
       "      <td>1412.823364</td>\n",
       "      <td>11339.787109</td>\n",
       "      <td>2354.402832</td>\n",
       "      <td>11625.394531</td>\n",
       "      <td>...</td>\n",
       "      <td>-2141.852295</td>\n",
       "      <td>-2590.605957</td>\n",
       "      <td>-2162.712891</td>\n",
       "      <td>-2595.548828</td>\n",
       "      <td>-2197.846191</td>\n",
       "      <td>-2502.833496</td>\n",
       "      <td>-2195.032227</td>\n",
       "      <td>-2491.998047</td>\n",
       "      <td>-2228.847412</td>\n",
       "      <td>3_austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11730.674805</td>\n",
       "      <td>-6021.035156</td>\n",
       "      <td>12871.799805</td>\n",
       "      <td>-7124.366211</td>\n",
       "      <td>12060.113281</td>\n",
       "      <td>-7679.387207</td>\n",
       "      <td>12143.309570</td>\n",
       "      <td>-7257.948730</td>\n",
       "      <td>11919.484375</td>\n",
       "      <td>-7445.813477</td>\n",
       "      <td>...</td>\n",
       "      <td>-484.069061</td>\n",
       "      <td>-2284.864746</td>\n",
       "      <td>-499.667755</td>\n",
       "      <td>-2202.729004</td>\n",
       "      <td>-450.200439</td>\n",
       "      <td>-2116.192627</td>\n",
       "      <td>-398.594299</td>\n",
       "      <td>-2026.723267</td>\n",
       "      <td>-368.494751</td>\n",
       "      <td>4_austin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             v0            v1            v2            v3            v4  \\\n",
       "0   2966.430664  -9985.373047    697.852295 -10905.495117    690.802124   \n",
       "1 -14110.257812   1248.141846 -13425.822266   1427.882446 -14444.098633   \n",
       "2   6244.087891  -9125.590820   3489.904785 -10084.924805   4511.722168   \n",
       "3   1807.790161  12150.986328   4077.757080  11414.631836   1885.708008   \n",
       "4  11730.674805  -6021.035156  12871.799805  -7124.366211  12060.113281   \n",
       "\n",
       "             v5            v6            v7            v8            v9  ...  \\\n",
       "0 -10871.316406    -76.476784 -10835.010742   -160.795670 -10610.087891  ...   \n",
       "1   1370.556519 -14100.422852   1362.783325 -14071.736328   1510.558472  ...   \n",
       "2 -10015.958984   4397.600098  -9890.113281   3239.341309  -9783.153320  ...   \n",
       "3  11301.711914   1412.823364  11339.787109   2354.402832  11625.394531  ...   \n",
       "4  -7679.387207  12143.309570  -7257.948730  11919.484375  -7445.813477  ...   \n",
       "\n",
       "          v111         v112         v113         v114         v115  \\\n",
       "0  1372.910889  1810.574585  1546.528076  1830.382812  1617.615112   \n",
       "1  2224.956543  2962.765625  2215.879639  2998.319824  2205.225098   \n",
       "2   602.991272  -703.001160   714.663147  -719.726807   774.714661   \n",
       "3 -2141.852295 -2590.605957 -2162.712891 -2595.548828 -2197.846191   \n",
       "4  -484.069061 -2284.864746  -499.667755 -2202.729004  -450.200439   \n",
       "\n",
       "          v116         v117         v118         v119        ID  \n",
       "0  1960.792969  1653.945923  1995.821899  1651.798950  0_austin  \n",
       "1  3001.184814  2196.748047  2946.293457  2248.370117  1_austin  \n",
       "2  -622.440613   821.556763  -489.944244   834.670654  2_austin  \n",
       "3 -2502.833496 -2195.032227 -2491.998047 -2228.847412  3_austin  \n",
       "4 -2116.192627  -398.594299 -2026.723267  -368.494751  4_austin  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmPredFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MSE: 4022490.07270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcb3c223ab97c6437cfd6f554c901fa5c15e7f782458399862988fe58f6c8db1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('PytorchVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
